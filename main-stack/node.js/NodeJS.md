# Самообучающийся материал по Node.js

## Оглавление

- [Введение](#введение)
- [Зачем нужен Node.js](#зачем-нужен-nodejs)
- [Ключевые особенности Node.js](#ключевые-особенности-nodejs)
- [Модули в Node.js](#модули-в-nodejs)
  - [Какие модули бывают](#какие-модули-бывают)
    - [IIFE](#IIFE)
    - [CommonJS](#CommonJS)
    - [EcmaScript modules](#ESM)
  - [Способы взаимодействия с путями](#работа-с-url)
    - [Глобальные переменные](#глобальные-переменные)
  - [Модульная система](#module-system)
    - [process](#module-system-process)
    - [events (событийный механизм)](#module-system-events)
    - [file system (работа с файлами)](#module-system-file-system)
    - [streams (работа с потоками данных)](#module-system-streams)
    - [os (информация об ОС)](#module-system-os)
    - [http (создание сервера)](#module-system-http)
    - [timers & related](#module-system-timers-and-related)
- [Подробнее про streams (работу с потоками данных)]()
    - [Понятие стримов](#понятие-стримов);
    - [Преимущество стримов](#преимущество-стримов);
    - [Какие есть виды стримов](#виды-стримов);
    - [С какими видами данных работают стримы](#данные-стримов);
    - [Подробнее про виды стримов](#подробнее-про-виды-и-данные-стримов);
      - [Writable stream](#writable-stream);
          - [Writable api event emitter](#writable-api-event);
          - [Writable полезные свойства](#writable-полезные-свойства);
      - [Readable stream](#readable-stream);
          - [Readable mode](#readable-mode);
          - [Readable api event emitter](#readable-api-event);
      - [Duplex stream](#dublex-stream);
      - [Transform stream](#transform-stream);
    - [Полезные фитчи стримов](#полезные-фитчи-стримов)

---

<a id="введение"></a>
## Введение

Node.js - среда выполнения js-кода на сервере. У него есть особая среда, например когда вы можете писать js-код, который будет взаимодействовать с файловой системой, с операционной системой благодаря которой мы можем, использовать js-код не только в браузере.

<a id="зачем-нужен-nodejs"></a>
## Зачем нужен Node.js

1. Когда мы хотим построить input, output - интенсивное приложение. Это означает, что есть задачи, которые не имеют так много вычислений, но при этом очень много данных идет на вход и много нужно отдавать на выход. Например - API (что-то отдают на фронт, получают с него запросы, делают несложные действия - например достать что-то из базы, что-то туда записать и отдать на фронт результат);

2. Когда мы хотим отдавать какие-то данные по частям (data streaming applications) - например мы можем отдавать видео, какие-то другие данные в потоке;

3. CLI (Command line interface) applications - это интерфейс командной строки. Если нам не нужен UI, и какая-то красивая графика и мы хотим чтобы наше приложение выполняло какие-то действия;

4. IoT (Internet of things) - устройство для умного дома, которое контролирует освещение, для контроля температуры в доме, включения лампочек и т.д. А в node-js он используется для применения в микроконтроллерах;

5. Cloud - если мы захотим использовать такие cloud провайдеры как Amazon Web Services или google cloud platform и microsoft azure, то с помощью него (node.js) мы можем писать лямбды функции, и мы можем писать приложения, которые там будем разворачивать;

<a id="ключевые-особенности-nodejs"></a>
## Какие есть ключевые особенность у Node.js

1. **Среда выполнения JavaScript**. Node.js позволяет выполнять JavaScript-код вне браузера, на сервере.

2. **Движок V8**. Node.js использует движок V8 от Google, который применяет JIT-компиляцию (Just-In-Time). Это позволяет очень быстро компилировать и выполнять код.

3. **Однопоточная модель с Event Loop**. В отличие от сред, где под каждый запрос создается отдельный поток (что потребляет много памяти и ресурсов), Node.js использует однопоточную модель. В её основе лежит Event Loop (цикл событий), который обрабатывает события и асинхронные операции. Крайне важно не блокировать его выполнением тяжелых синхронных операций.

4. **Кроссплатформенность**. Node.js позволяет писать код, который будет работать на разных операционных системах (Windows, Linux, macOS) и устройствах (компьютеры, серверы, иногда даже микроконтроллеры).

5. **Событийно-ориентированная архитектура (Event-Driven Architecture)**. Node.js построен на событиях, что идеально подходит для обработки множества одновременных операций ввода-вывода (например, запросов к базе данных, сетевых вызовов).

6. **Высокая масштабируемость (Scalability)**. Благодаря своей архитектуре Node.js очень хорошо масштабируется. Можно легко создавать новые экземпляры приложения с помощью дочерних процессов (child processes), выделять тяжелые задачи в отдельные потоки (worker threads) и масштабировать приложение с помощью кластеризации (cluster).

7. **Богатый встроенный API**. Node.js обладает обширной стандартной библиотекой, содержащей множество встроенных модулей (для работы с файловой системой, сетью, HTTP и т.д.). Это предоставляет готовый функционал для решения основных задач.

<a id="модули-в-nodejs"></a>
## Модули в Node.js

В node.js любой файл считает модулем. Модуль в свою очередь это такой способ организации кода, когда отдельный какой-то функционал помещается в отдельный файл, и соответственно содержимое этого файла оно экспортируется / импортируется в другие файлы (модули).

### Основные преимущества использования модулей

1. Кодовая база делится на различные файлы, что упрощает понимание каждого куска кода;

2. Облегчается переиспользование кода - если модуль написан правильно, то есть он в себя принимает какие-то входные данные, он что-то с ними делает и отдает какие-то выходные данные;

3. Изоляция кода и его сокрытия - мы знаем, что модуль требует для своей работы, что отдает и внутри он что-то делает, но если это хорошо написанный модуль, то по сути не важно как реализованно именно его внутренний код. И удобно нам как скрывать эту функциональность и изолировать;

4. Модули позволяют нам лучше управлять зависимостями;

### Существует несколько способов написание модулей

<a id="IIFE"></a>
<details>
<summary>1. Через IIFE</summary>

```js
const IIFE_module = (() => {
  let innerVariable = 'Secret value!';

  const publicInterface = {
    getValue() {
      return innerVariable;
    },
    setValue(newValue) {
      if (typeof newValue === 'string') {
        innerVariable = newValue;
      } else {
        innerVariable = "DEFAULT"
      }
    }
  }

  return publicInterface
})();

console.log(IIFE_module.getValue())

IIFE_module.setValue('new str')
console.log(IIFE_module.getValue())

IIFE_module.setValue(12334)
console.log(IIFE_module.getValue())
```
</details>

<a id="CommonJS"></a>
<details>
<summary>2. Через CommonJS</summary>

CommonJS, где импорт осуществляется через `require(moduleName)`, а экспорт - через `exports` или `module.exports`.
**Разница между `exports` и `module.exports`:**
- И `exports`, и `module.exports` изначально ссылаются на один и тот же пустой объект
- `exports` - это просто переменная-ссылка на `module.exports`
- При присваивании `exports = 'string'` мы перезаписываем эту ссылку, теряя связь с `module.exports`, поэтому модуль вернет пустой объект
- При использовании `exports.a = 'string'` мы модифицируем общий объект, поэтому свойства доступны
- `module.exports` можно безопасно перезаписывать полностью

**Работа `require()`:**
Синхронная функция `require(moduleName)` ищет модули в порядке:
1. Встроенные модули Node.js (fs, path и т.д.)
2. По относительным/абсолютным путям (`./`, `../`, `/`)
3. В папке `node_modules` текущей директории и родительских директорий

**Кеширование:** Модуль загружается только один раз при первом вызове `require()`, затем результат кешируется.
</details>

<a id="ESM"></a>
<details>
<summary>3. Через ESM (EcmaScript modules)</summary>


Выделяют следующие способы установки модуля:

a. Можно ко всем файлам вместо js установить .mjs и у нас будет использоваться import;

b. package.json написать type и выбрать "module" - так он будет понимать, что мы используем модули;

c. Через терминал написав node --input-type=module nameFile;

Есть несколько видов импортов:

- `import default from "module-name";` - дефолтный экспорт
- `import * as name from 'module-name'` - возьмется все импорты и запишется в переменную name
- `import { name_01, name_02 as Loge } from 'module-name'` - импорт с деструктиризацией и запись в переменную Loge
- `import defaultExport, { export [, [...] ] } from module-name`
- `import module-name` по типу `require('./')`;
- Динамические импорты: `import("/module-name.js").then(module => {...}).catch(error => {})`

Есть несколько видов экспорта:
- Классический экспорт `const a = 2
export { a }` и экспорт переменной через `export const a = 2`;
- Переименовка экспорта `export { a as name, b }; import { name } from 'name-file';`
- Экспорт по дефолту - когда нам необходимо экспортировать определенную функцию - `const a = 1` или просто `export default a`.
- Можно экспортировать одно по умолчанию, а другие нет - `export { a as default, b, c}`

Как работают импорты, они имеют 3 фазы:
- Construction (parsing) - в ней ищутся все импорты модулей и рекурсивно загружается контент со всех модулей
- Instantiation - для каждой сущности сохраняется именованная ссылка в памяти, но в ней пока не привязываются какие-то значения. Они помогают взаимоотношения между импортами
- Evaluation - фаза выполнения. На этой фазе node берет и выполняет код всех этих сущностей инстанцированных используя вот эти связи и после этого у нас возможен запуск кода в загружаемом модуле. Потому что все вычисления были выполнены.

Ключевые особенности:
- Native JS modules (через import)
- Импорт асинхронный
- Импорты не работают в блоках кода
- this будет undefined
- Есть import.meta
- Нет default __dirname, __filename, require, exports, module. Но заменить можно след.образом dirname:

```js
import { fileURLToPath } from 'url';
import { dirname } from 'path'; 

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename)
```

Аналог require:

```js
import {createRequire} from 'module'

const require = createRequire(import.meta.url);
```

- Ecmascript modules такие же как в браузере
</details>

---

<a id="работа-с-url"></a>
### Способы взаимодействия с путями

Существует несколько способов взаимодействия с путями, например мы можем относительно вызвать его `./files/fileToRead.txt`, но это плохая практика, так как на разных операционных систем используется разные виды слешов. Например в линуксе есть обратный слеш `\`, и это надо учитывать

```js
import path from 'path';

const fileToRead = path.join('files', 'fileToRead.txt');        // files/fileToRead.txt (Позволяет склеивать несколько участков пути)

path.resolve('src', 'app.js');                                  // '/full/path/to/current/dir/src/app.js' (создает абсолютный путь, начиная с текущей рабочей директории)

path.extname('file.txt');                                       // '.txt' (Получить расширение файла)

path.basename('/path/to/file.txt');                             // 'file.txt' (Получить имя файла с расширением)

path.basename('/path/to/file.txt', '.txt');                     // 'file' (Получить имя файла без расширения)

path.dirname('/path/to/file.txt');                              // '/path/to'  (Получить директорию)

path.normalize('/path//to/../file.txt');                        // '/path/file.txt'  (Нормализация пути (убирает лишние символы))

path.isAbsolute('/path/to/file');                               // true (Проверка абсолютный ли путь)

path.isAbsolute('./file');                                      // false (Проверка абсолютный ли путь)
```

<a id="глобальные-переменные"></a>
#### В node.js есть две глобальные переменные:

`__dirname` - строка, которая содержит путь к текущей директории. То есть на любом устройстве мы можем получить абсолютный путь от корня до дериктории, в которую мы используем эту глобальную переменную.

```js
console.log(path.join(__dirname))         // ../node-nodejs-basics/src/fs/read.js 
console.log(path.join(__dirname, ".."))   // ../node-nodejs-basics/src/fs 
```

Также стоит уточнить, что в ES-модулях не доступен dirname, вместо этого используется `import.meta.url`

```js
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
```

3. Создать new URL, у которого внутри два параметры - если мы пишем с одним параметром, то это абсолютная путь, если задействуем второй путь, то это относительный путь + базовый url

```js
const base = 'https://example.com/api/v2';

new URL('users', base);        // → https://example.com/api/v2/users
new URL('/users', base);       // → https://example.com/users
new URL('./stats', base);      // → https://example.com/api/v2/stats
new URL('../v1/users', base);  // → https://example.com/api/v1/users
```

```js
const fileToRead = new URL('./files/fileToRead.txt', import.meta.url)
// file:///C:/Users/mulwo/Desktop/pet-project/node-nodejs-basics/src/fs/read.js
```

---

<a id="module-system"></a>
### Модульная система

Node.js использует модульную систему. То есть вся встроенная функциональность разбита на отдельные пакеты или модули. Модуль представляет блок кода, который может использоваться повторно в других модулях. А так модули делятся на 3 типа: 

1\. `Packages (3-rd party)` - внешние модули, которые мы устанавливаем;

2\. `Core modules (built-in)` - это модули которые установлены по умолчанию внутри node-js, например мы импортируем их - fs, streams и.т.д.; 

3\. `Модули собственно кода` - когда мы пишем приложение на node.js мы реализуем функционал в виде какого-то кода и этот код разделяется по файлам, соответственно и эти файлы будут являться модулями

### Примеры методов использование модулей

<a id="module-system-process"></a>

`Process` - предоставляет полные данные о системе, параметрах запуска, переменных окружении и потребялемых процессом ресурсах. Он глобальный и импортировать его не стоит

1. `process.pid` - получить id текущего процесса в котором запускается node-js;
2. `process.argv` - получаем аргументы командной строки с которым было запущено  приложение;
3. `process.report.writeReport()` - получаем отсчет нашего процесса - о том сколько он употребляет памяти, в каком окружении он работает;
4. `process.on("SIGTERM", () => {...})` - можем подписываться на системные сигналы;
5. `process.exit()` - можем завершить текущий процесс;

<a id="module-system-events"></a>

`Events` - позволяет реализовывать API, подписки на события и их эмита. EventEmitter() - это такая сущность, которая позволяет подписываться на события и их емитить. 

```js
const EventEmitter = require('events');
const calculator = new EventEmitter();
calculator.on('sum', (a, b) => console.log(`Result is ${a + b}`))
calculator.emit('sum', 1, 3 )
```

<a id="module-system-file-system"></a>

`File system` (файловая система) - представляет собой абстракцию в node-js файловых систем вашей хостовой машины и позволяет вам выполнять различные полезные операции. Например получения информации о файла 

```js
const fs = require('fs/promises');
const fileStats = await fs.stat('photos/cute/funny-cat.jpg');

console.log(fileStats.isFile())    // ? Проверка на является ли файл - файлом?
console.log(fileStats.size)        // ? Размер файла в битах
console.log(fileStats.birthname)   // ? Дата создания файла
```

<a id="module-system-streams"></a>

`Streams` - когда мы используем некий интерфейс для того, чтобы работать с данными по частям - не читать сразу весь файл, а разделить его на части. Например когда мы хотим прочитать данные из request-body, записывать данные, duplex работают как для чтения так и для записи

```js
const {Readable} = require('stream');

class MyAwesomeReadStream extends Readable {
  constructor(options) {
    super(options)
    // Initialization
  }

  _read(n) {
    // Reading Logic
  }
}
```

<a id="module-system-os"></a>

`Os` - информация об операционной системе и об аппаратном обеспечении компьютера, на котором работает Node.js, только в виде чтения

```js
const os = require('os');

console.log(os.cpus())                  // ? Получаем список нашим процессов
console.log(os.networkInterfaces())     // ? Получаем все network интерфейсы, которые привязаны к текущему адресу
console.log(os.freemem())               // ? Кол-во свободной памяти в системе;
```

<a id="module-system-http"></a>

Для сетевых запросов мы используем http - модуль который позволяет обрабатывать (как получать так и отправлять) запросы, то есть мы можем создать http сервис, 

```
const http = require('http');
const server  = http.createServer((request, response) => {
  request.end("Hello from Node.js!")
})
server.listen(4000)
```

<a id="module-system-timers-and-related"></a>

Timers & related (отложенное исполнения callback)
1. setTimeout(() => {...}, 500)
2. setInterval(() => {...}, 500)
3. setImmediate(() => {...}, 500) - выполняется всегда после пол.фазы евентлупа, которые забирает новые инпут и отпут события с коллбеками. 
4. process.nextTick(() => {...}, 500) - попадают специальные приоритетные очереди, они выполняются быстрее всего
5. queueMictotask(() => {...}, 500) - она попадает в очередь микротасок, туда же попадают и промисы, которые будут выполняться за nextTick внутри приоритетных очередей

Прочитать - https://nodejs.org/en/learn/asynchronous-work/event-loop-timers-and-nexttick


---

<a id="понятие-стримов"></a>
`Stream` - абстрактный интерфейс для работы с потоковыми данными. Это унифицированный программный интерфейс для чтения или записи данных, сокетов и переносов данных между процессами. 

<a id="преимущество-стримов"></a>
У стримов есть следующие преимущество:

1\. Принцип разделения ответственности. Он создает маленькие компоненты, которые делают что-то одно, но они делают это очень хорошо. Таким образом мы можем менять код изолированного чего-то одного, что позволяет лучше управлять нашим приложением

2\. Гибкость, их можно легко подключать подключать, перенаправлять (когда направляем какие-то данные из одного источника в несколько мест назначения)

3\. Эффективность по времени и памяти, так как они получают данные по кусочкам, они потребляет небольшое кол-в памяти и это потребления памяти является фиксированным потому что поток который через stream он равномерен.

---

<a id="подробнее-про-виды-и-данные-стримов"></a>

### Виды и данные стримов

В node.js 4 основных видах стрима: writable (нужен для писания данных), readable (нужен для чтения данных), duplex (могут как читать так и писать), transform (вычислять на основе входных данных - выходные данные и отдавать их дальше). Стримы работают с двумя видами данных - это буфферы (или строки) и объекты. 

Буфферы - абстрактный способом хранения последовательности данных фиксированной длины. Буфферы - такие объекты, которые нужны для представления данных фиксированной длины. Это также подкласс unitInArray. Способы создания буфферов. В начале нам необходимо импортировать буфер `const { Buffer } = require('buffer')`;

| Код | Описание |
|-----|----------|
| `const emptyBuffer = Buffer.alloc(42);` | Если передаем 1 аргумент, то создается пустой буфер, который имеет размер 42 байта |
| `const filledBuffer = Buffer.alloc(42, 1);` | Если передаем 2 аргумента, то создается буфер, который имеет размер 42 байта содержащих единицу |
| `const fasterCreatedBuffer = Buffer.allocUnsafe(42, 1);` | Еще 1 способ создания буфера. Он небезопасный, работает быстрее, но может захватить больше области памяти в которых уже имеются какие-то данные и прежде чем с ним работать нужно эти данные отчистить |
| `const bufferFromStringDefaultUTF8 = Buffer.from('javascript');` | Буфер может быть создан из строки |
| `const bufferFromStringLatin1 = Buffer.from('javascript', 'latin1');` | Также вторым аргументом можем передавать кодировку |
| `const bufferFromArray = Buffer.from([1,2,3]);` | Буфер также можно создавать из массива |

[Пример кода](./streams/01-buffer.js), а также подробнее можно почитать в [документации](https://nodejs.org/api/buffer.html)

Буферы также считаются итерируемыми объектами - то есть с помощью цикла for of мы можем перебрать их. Все стримы используют какие-то внутренние буфферы для хранения каких-то данных. Кол-в данных определяется размером буффера. Чтобы узнать порог ("ограничение по памяти") можно использовать хай watermark. 

<a id="writable-stream"></a>
<h2 align="center">Writable streams</h2>

Writable streams наследники базового класса одного-именного writable, которые находится в модуле стримы. И они предоставляют два метода с которыми можно работать - метод `WRITABLE.WRITE` и `WRITABLE.END`. Какие есть стримы во writable: 

| Категория | Поток/Метод | Назначение |
|-----------|-------------|------------|
| **HTTP** | `request` (клиентская сторона) | Отправка запроса на клиентской стороне;|
| | `response` (серверная сторона) | Ответ на серверной стороне |
| **Процессы**  | [`process.stdout`](./streams/methods/process/stdout.js) | Выводит данные |
| | [`process.stderr`](./streams/methods/process/stderr.js) | Выводит ошибки |
| **Дочерние процесс** | `child.stdin` | Для передачи данных дочернему процессу (отправляет данные другой программе). |
| **Файловая система** | `fs.createWriteStream()` | Запись файла |
| **Трансформации** | `zlib` | Сжатие и распаковка данных |
| | `crypto` | Шифрование и дешифрование данных |
| **Сеть** | `TCP sockets` | Чтение данных из сетевых соединений |

<a id="writable-api-event"></a>

Все стримы, включая writable использует API eventemitter (встроенный модуль в node.js, который предоставляет функционал нам для работы с событиями), позволяет нам эмитеть некие события, генерировать, подписаться и т.д. Основной список событий, который эмитит у нас writable stream: 

| Событие | Что делает | Пример кода |
|-----------|-------------| -------------| 
| *.error* | события эмитится когда происходит какая-то ошибка и для обработки ошибки мы можем подписать на это события | 
| *.drain* | когда внутренний буфер заполняется, то с помощью данного метода когда буфер освободится он сразу же запишет какие-то значения | 
| *.close* | когда стрим ресурс закрывается или завершается и он не может писать данные - метод writable.destroy | 
| *.finish* | когда процесс записи завершается и все данные уже записаны пример writable.end() | 
| *.pipe* | метод для соединения двух потоков - readable stream и writable stream | [Пример кода](./streams/methods/pipe.js) |
| *.unpipe* |  метод для отсоединения двух потоков - readable stream и writable stream. Используем когда нужно переключить поток, отменить действие, когда достигает лимита | [Пример кода](./streams/methods/pipe.js) |


<details>
<summary>Пример кода</summary>

```js
const fs = require('fs');

// Читает из /01-buffer.js и записывает в другой файл
const rs = fs.createReadStream('./01-buffer.js');
const ws = fs.createWriteStream('new_file.txt');

// Подписываемся на все события
ws.on('close', () => console.log("Writable stream has been closed"));
ws.on('finish', () => console.log("Writable streams has been finished"));
ws.on('pipe', () => console.log("Piped to readable stream"));
ws.on('unpipe', () => console.log("Unpiped from readable stream"));

/*
  Вот что выведется в console.log
  
  В начале отработал события подсоединение к стриму => 
    1. Piped to readable stream, 
  затем у нас стрим завершился обработал события close =>
    2. Writable streams has been finished
  затем у нас обработался finish, потому что запись завершилась =>
    3. Unpipe from readable stream
  а в конце уже обработался close => 
    4. Writable stream has been closed
*/

ws.on('error', (err) => console.log(`Error occurred: ${err}`));
ws.destroy(new Error("Ooops"))

rs.pipe(ws);
```
</details>

<a id="writable-полезные-свойства"></a>

### Полезные свойства

Помимо событий у него есть еще методы и какие-то полезные свойства: 

| Свойство | Что делает или для чего нужен | Пример кода | 
| -------- | ------------------------------| ----------- |
| *.write(что надо записать, callback, кодировка (по умолчанию UTF-8))* |  возвращает true/false. Если false то у нас переполнился внутренний буффер и мы должны что-то с этим сделать прежде чем писать. Например куда-то отдать эти данные | [Пример кода](./streams/writable/features/write.js) |
| *.end* | метод когда мы хотим записать какой-то последний кусочек данных, и после этого стрим у нас будет закрыт | [Пример кода](./streams/writable/features/end.js) |
| *.destroy() | делает грубое закрытие стрима (ломает). В качестве аргумента он может принимать ошибку и если мы его передали, то эту ошибку можно обработать через error | [Пример кода](./streams/writable/features/destroy.js) |
| *.cork и uncork* (редко) | Метод `.cork` - он заставляет все записанные данные буфферизоваться в памятиб он никуда никакие данные не запишет пока не будет вызван метод `.uncork`. Они работают в паре и стоит отметить, у нас кол-во `cork()` должно совпадать с `uncork()`, то есть если у одного два, то и другого должно быть столько | [Пример кода](./streams/writable/features/corkAndUnkork.js) |


Полезно использовать тогда когда chunks быстро записываются и мы не хотим их сразу быстро отправлять, мы в начале их буферизуем и нам не нужно дожидатся выполнения чанков и мы отдадим сразу все на выходе с помощью метод uncork();
 
Другие методы:
| Метод | Описание |
|-----|----------|
| writable.setDefaultEncoding(encoding) | Установить дефолтную кодировку для строк с которыми он будет работать |
| writable.destroyed | Показывает (true/false) был ли вызван метод ,destroy | 
| writable.writable | Показывает можно ли еще стрим использовать для того, чтобы писать |
| writable.writableEnded | Показывает был ли вызван метод .end |
| writable.writableCorked | Показывает был ли вызван метод .cork и при этом не вызван ли метод .uncork |
| writable.writableHighWaterMark | Можем получить значения HighWaterMark для этого стрима | 
| writable.writableLength | Показывает число, байт или объектов готовые к записи |
| writable.writableNeedDrain | Флаг, который показывает нужно ли чистить наш внутренний буфер |
| writable.writableObjectMode | Геттер для object-мода, если у нас true, то стрим у нас работает в object-mode если нет, то работает со строками


<a id="readable-stream"></a>

<h2 align="center">Readable streams</h2>

Readable streams нужны нам для чтения данных. Они могут приходить постепенно (например, видео с сервера) или быть доступны сразу. К readable streams относится: 

| Категория | Поток/Метод | Назначение |
|-----------|-------------|------------|
| **HTTP** | `request` (серверная сторона) | Чтение входящих HTTP-запросов |
| | `response` (клиентская сторона) | Чтение ответов сервера |
| **Процессы** | [`process.stdin()`](./streams/methods/process/stdin.js) | Стандартный поток ввода |
| | `child process.stdout` | Стандартный вывод дочернего процесса |
| | `child process.stderr` | Поток ошибок дочернего процесса |
| **Файловая система** | `fs.createReadStream()` | Чтение файлов через потоки |
| **Трансформации** | `zlib` | Сжатие и распаковка данных |
| | `crypto` | Шифрование и дешифрование данных |
| **Сеть** | `TCP sockets` | Чтение данных из сетевых соединений |

<a id="readable-mode"></a>
<h2 align="center">Readable stream modes</h2>

1\. `Paused mode` - когда он находится в остановленном состоянии. Он не читает данные, чтобы их буфферизировать, чтобы их прочитать нам надо явно вызвать метод readable. Когда мы только создаем стрим fs.createStream - он не читает данные, он находится в paused mode, надо явно указать чтобы он начал читать 

2\. `Flowing mode` - когда он находится в текущем состоянии (в состоянии потока). Когда readable stream читает данные автоматически и отдает их дальше так быстро как это возможно и метод внутренний readable.read он вызывается автоматом

Для того, чтобы переключить с paused mode на flowing mode можно: `повесить обработчик события на data` или `Вызвать метод readable.resume (продолжить чтения)` или `Использовать readable.pipe(writable)`

А для того чтобы перевести его обратно в pause mode: `мы должны вызвать readable.pause метод, который его остановит, однако это не сработает если readable куда-то запайпили. Если у него есть какие-то пайпы, то необходимо отключить все через readable.unpipe.`

Что нужно понимать - Readable стрим не отдает данные никуда до тех пор пока не реализовали механизм, который их поглощать. 

<a id="readable-api-event"></a>
<h2 align="center">Readable api event emitter</h2>

Он тоже использует API event-emitter и имеет список событий

| Событие | Что делает | Пример кода |
|---------|------------|-------------|
| **`.data`** | При подписке на событие мы можем читать данные. Stream автоматически переходит в `Flowing mode` и нам не надо вручную дергать метод `readable.read`. | [Пример кода](./streams/readable/data.js) |
| **`.readable`** | Имитится, когда можно прочитать данные. Пользователь должен самостоятельно вызвать `readable.read()` для получения данных, у которого есть необ.параметры `([size])`, кол-во байтов для чтения. | [Пример кода](./streams/readable/readable.js) |
| **end** | Имитится, когда больше нет данных для чтения. Срабатывает только после полной обработки всех данных. | — |
| **`.pause`** | Имитится при вызове метода `readable.pause()`, если `readable.flowing` не равен `false`. Используется для приостановки потока в flowing mode. | — |
| **`.resume`** | Имитится при вызове метода `readable.resume()`, если `readable.flowing` не равен `true`. Используется для возобновления потока. | [Остановка и возобновление стрима](./streams/readable/pauseAndResume.js) |
| **`.error`** | Обработка ошибок, возникающих при работе с потоком. | — |
| **`.close`** | Срабатывает, когда стрим закрывается и все ресурсы освобождаются. | — |
|  **`.pipe`** | метод для соединения двух потоков - readable stream и writable stream |x [Пример кода](./streams/methods/pipe.js) |
| **`.unpipe`** |  метод для отсоединения двух потоков - readable stream и writable stream. Используем когда нужно переключить поток, отменить действие, когда достигает лимита | [Пример кода](./streams/methods/pipe.js) |

<details>
<summary>Код с pipe и unpipe</summary>

```js
const {createWriteStream} = require('fs');

const readableFromTerminal = process.stdin;
const writableToTerminal = process.stdout;
const writableToFile = createWriteStream('./output.txt');

readableFromTerminal.pipe(writableToTerminal)
readableFromTerminal.pipe(writableToFile)

readableFromTerminal.on('data', (chunk) => {
  const chunkStringified = chunk.toString();

  // Если наша строка не содержит unpipe terminal, то повторное написание любых слов выводится в консоль, после написать вывода никакого нету
  if (chunkStringified.match('unpipe terminal')) readableFromTerminal.unpipe(writableToTerminal)
  
  // А после него пишем это и у нас завершается выполнения кода
  if (chunkStringified.match('unpipe file')) readableFromTerminal.unpipe(writableToFile)
})
```
</details>

Что лучше выбрать readable.read в сочетании с обработкой события readable или подписку на события read - Оба варианта хороши, но лучше выбрать один стиль для всего, но предпочтительнее pipe, unpipe, a readable.read нужен для большего контроля - когда вы  хотите определять как вы хотите вызвать ваш метод read сколько вы хотите считать, что вы хотите сделать с этими данными, при использовании можно достичь большего перформанса, однако нужно знать подводные камни

Другие методы и свойства:

| Метод | Что делает | Пример кода |
|-------|------------|-------------|
| **`.destroy([error])`** | Уничтожает поток и принимает опциональный параметр `error` (объект ошибки) аналогично Writable потоку. Освобождает все ресурсы, связанные с потоком. | - |
| **`.unshift(chunk)`** | Возвращает обратно прочитанный chunk во внутренний буфер потока для последующего чтения. Полезно при парсинге данных, когда нужно "откатить" обработку. | - |
| **`.wrap(legacyStream)`** | Используется для работы с legacy-кодом. Позволяет создать современный Readable Stream на основе устаревшего потока, который будет использоваться как источник данных. | - |
| **`.isPaused()`** | Возвращает `true`, если поток остановлен (находится в paused mode), и `false` если поток активен (flowing mode). | - |
| **`[Symbol.asyncIterator]()`** | Создает асинхронный итератор для использования с `for await...of`. Автоматически предотвращает уничтожение потока при досрочном завершении цикла (break, return). Также может завершить поток при необходимости. | - |
| **`.readable`** | Флаг, показывающий, что поток находится в состоянии, пригодном для чтения данных. Возвращает `true` если поток можно читать, `false` если поток закрыт или уничтожен. | - |
| **`.readableAborted`** | Флаг, показывающий, что поток был принудительно уничтожен через метод `.destroy()` до полного чтения всех данных. | - |
| **`.readableDidRead`** | Флаг, показывающий, было ли выполнено хотя бы одно чтение данных из потока после его создания. | - |
| **`.readableEncoding`** | Возвращает кодировку, которая была установлена для потока через метод `.setEncoding()` или при создании. | - |
| **`.readableEnded`** | Возвращает `true`, если поток завершил чтение (событие `'end'` уже произошло). Показывает, что все данные были прочитаны. | - |
| **`.readableFlowing`** | Геттер, показывающий текущее состояние потока: `null` (начальное состояние, не подписан на события), `true` (flowing mode, данные поступают автоматически), `false` (paused mode, чтение приостановлено). | - |
| **`.readablePaused`** | Аналогичен `.isPaused()`. Возвращает `true`, если поток остановлен (находится в paused mode). | - |
---




<a id="duplex-streams"></a>

### Duplex streams

Это стримы, которые работают в два направления - writable interface и readable interface, то есть они могут и читать и писать. Примеры, где используются данные стримы - это `TCP sockets`, `zlib streams`, `crypto streams`

У duplex стрима есть специфичность и это `duplex.allowHalfOpen` - флаг, значения которого если будет false, то тогда когда стрим автоматически завершает свою writable часть, если завершится его readable часть. То есть разрешить ли стриму быть наполовину открытым

---

<a id="transform-streams"></a>

### Transform streams 

Это такие стримы, которые нужны для преобразования данных (разновидность duplex стримов - все интерфейсы также есть и transform). Они генерируют некий output основываясь на инпуте и это необязательно просто преобразование входных данных и отдачи в каком-то измененном виде. Например - можно отдавать больше данных чем получили, также и наоборот, либо можно вообще не отдавать данных в определнных случаях или можно то отдавать, то не отдавать. Смысл в том, что данные вычисляются выходные на основе входных при помощи какой-то внутренней реализации. Вот пример простого transform стрима, которая переварачивает строку

```js
const { Transform, pipeline } = require('stream');

const readable = process.stdin;
const writable = process.stdout;

const transform = new Transform({
    transform(chunk, eng, callback) {
        // Считываем чанк, приводим его к строке и убираем трим для убирания служеб.переводов строки и возврата корретки
        const chunkStringified = chunk.toString().trim();
        const reversedChunk = chunkStringified.split("").reverse().join('');
        this.push(reversedChunk + "\n");
        callback()
    }
})

pipeline(readable, transform, writable, err => console.log(`Error: ${err}`))
```

Есть также разновидность transform streams - это passThrough - он не преобразует данные, которые него идут, а используется для мониторинга внутри вашего пайплайна


---

<a id="полезные-фитчи-стримов"></a>

### Полезные фитчи стримов

1. `Stream.finish` - функция, которая принимает stream и получает оповещения когда stream завершается. Если это readable stream, то он больше не может читать, если writable stream, то он не может больше писать или если стрим завершился с ошибкой. Это полезно когда стрим может прерваться внезапно - например при HTTP сервера, когда мы передаем большой файл с клиента на сервер через запрос и внезапно пропадает интернет. [Пример кода находится здесь](./streams/05-stream.finished.js)

2. `Stream.pipeline` - у него есть два метода использований:
- Если просто достаем из метода stream, то это коллбек версия после всего необходимо передать коллбек для обработки ошибок
- промифицированные версия пайплайна

```js
const processData = async () => {
  try {
    // Передаем два стрима один будет читать c инпута
    // а второй будет писать с оупута 
    await pipelinePromisified(
      createReadStream('./input.txt'),
      createWriteStream('./output.txt')
    )
    console.log('Success!');
  } catch (err) {
    console.error(`Error occured: ${err}`)
  } finally {
    console.log("DO SMTH IN THE END")
  }
}
```
Чем pipeline лучше чем pipe тем, что пайплан за собой почищает вещи - корректно уничтожает все стримы, все закрывает

3. Stream.readable.from - мы можем создавать стримы из итерируемых объектов. 

```js
import { Readable } = require('stream');

const iterable = {
  from: 1,
  to: 10,
  // Для того, чтобы объект был итерируемый у него должен iterator, который
  // должен возвращать объект, который содержит метод next
  [Symbol.iterator]() {
    return {
      current: this.from,
      last: this.to,
      // Данный метод опять должен возвращать объект, в котором будет flag - done
      // завершили мы итерацию или нет и какое-то value
      next() {
        if (this.current < this.last) {
          return {
            done: false,
            value: this.curren++
          }
        }

        return {
          done: true,
          value: this.curren
        }
      }
    }
  }
}

const readableFromIterable = Readable.from(iterable);
readableFromIterable.on('data', (chunk) => {
  console.log(chunk)
})
```

### Custom streams

Мы можем создавать свои стримы с помощью прототипного наследования js, но нужны они когда мы хотим что-то создать универсальное, в 95% задач нам уже доступно все и ничего не нужно создавать. Есть следующие моменты использования своих кастомных стримов - это то что там есть `прототипное наследование`, чтобы реализовать свой стрим вы должны наследвоатся от одного из базовых классов - stream readable, writable и т.д. и убедится в том, что они вызывают конструктор родительского класса через `super()`. `Common API` вы должны придерживатся его и третий принцип - `flexibility` (гибкость)

Для того, чтобы опции, которые мы передаем в конструктор нашего кастомного стрима, чтобы они работали мы должны передавать в родительнский конструктор - вызвав super, перед тем как мы что-то запишем в this в дочернем экземпляре. Также кастомный стрим не должен вызыватся снаружи, можно использовать только публичные методы

Создавать стримы можно двумя способами:

1. Упрощенный, когда мы достаем из модуля стрим - базовый класс и создаем его экземляр. Все что он делает - это записывает в process.stdout какой-то чанк и мы его пайпим к стидн

```js
const { Writable } = require('stream');

const myWritable = new Writable({ 
  write(chunk, enc, callback) {
    process.stdout.write(chunk);
    callback();
  };
})

process.stdin.pipe(myWritable);
```

2. Гибкий - когда наследуемся от базового класса

```js
const { Writable } = require('stream');

const myWritable extends Writable { 
  constructor(options = {}) {
    super(options);
  }

  _write(chunk, enc, callback) {
    process.stdout.write(chunk);
    callback();
  };
}

const myWritable = new MyWritable();
process.stdin.pipe(myWritable);
```

Более подробно можно прочитать из документации по созданию [writable streams](https://nodejs.org/api/stream.html#implementing-a-writable-stream), [reading streams](https://nodejs.org/api/stream.html#implementing-a-readable-stream), [duplex streams](https://nodejs.org/api/stream.html#implementing-a-duplex-stream), [transform streams](https://nodejs.org/api/stream.html#implementing-a-transform-stream)


---

Источники:

1. [Rolling scopes school -  NodeJS 2021Q2 Modules](https://www.youtube.com/watch?v=RXFOAqsWzFA);
2. [Rolling scopes school -  Node.js 2021Q4 Streams](https://www.youtube.com/watch?v=RXFOAqsWzFA);